{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from skimage import io, transform\n",
    "\n",
    "import os\n",
    "\n",
    "from project_code.utils import preprocessing\n",
    "from project_code.data.face_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 4699), started 0:02:53 ago. (Use '!kill 4699' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a4ce59b5e521fffb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a4ce59b5e521fffb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup tensorboard\n",
    "import tensorboard\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs\n",
    "\n",
    "# If you run this notebook locally, you can also access Tensorboard at 127.0.0.1:6006 now.\n",
    "\n",
    "# Clean up old logs\n",
    "if os.path.isdir('./runs/'):\n",
    "    import shutil\n",
    "    shutil.rmtree('runs/')\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\"\n",
    "writer = SummaryWriter('runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing.\n",
    "if False:\n",
    "    attributes = pd.read_csv('data/person.csv', sep=';')\n",
    "    \n",
    "    # Remove all people without pictures.\n",
    "    with_images, without_images = preprocessing.filter_without_images(attributes, 'data/front/front/')\n",
    "\n",
    "    without_images.to_csv(\"attributesPersonsNoImages.csv\", index=False)\n",
    "    with_images.to_csv(\"attributesPersonsWithImages.csv\", index=False)\n",
    "\n",
    "    # Use this when the people without images are already filtered out.\n",
    "    # (Which should be the case if you have the csv files)\n",
    "    #attributes = pd.read_csv(\"attributesPersonsWithImages.csv\")\n",
    "    \n",
    "    train_set, val_set, test_set = preprocessing.split_data(with_images, 0.8, 0.05)\n",
    "\n",
    "    train_set.to_csv(\"trainSet.csv\", index=False)\n",
    "    val_set.to_csv('valSet.csv', index=False)\n",
    "    test_set.to_csv(\"testSet.csv\", index=False)\n",
    "\n",
    "train_set = pd.read_csv(\"trainSet.csv\")\n",
    "val_set = pd.read_csv(\"valSet.csv\")\n",
    "test_set = pd.read_csv(\"testSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_code.networks.congregated_layers import *\n",
    "\n",
    "# Define a convolutional neural network\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, bilinear):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        self.n_channels = 3\n",
    "        self.bilinear = bilinear\n",
    "        \n",
    "        factor = 2 if bilinear else 1\n",
    "\n",
    "        self.inc = DoubleConv(self.n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = nn.Conv2d(64, self.n_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data.\n",
    "train_set = FaceDataset(csv_file=\"trainSet.csv\",\n",
    "                        root_dir='data/front/front',\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.Resize((48, 48)),\n",
    "                            transforms.ToTensor()\n",
    "                        ]))\n",
    "\n",
    "val_set = FaceDataset(csv_file=\"valSet.csv\",\n",
    "                      root_dir='data/front/front',\n",
    "                      transform=transforms.Compose([\n",
    "                          transforms.Resize((48, 48)),\n",
    "                          transforms.ToTensor()\n",
    "                      ]))\n",
    "\n",
    "test_set = FaceDataset(csv_file=\"testSet.csv\",\n",
    "                       root_dir='data/front/front',\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize((48, 48)),\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "trainloader = DataLoader(train_set, batch_size=4, shuffle=True, num_workers=0)\n",
    "valloader = DataLoader(val_set, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "# Show the data in Tensorboard\n",
    "dataiter = iter(trainloader)\n",
    "data = dataiter.next()\n",
    "img_grid = utils.make_grid(data['image'])\n",
    "writer.add_image('dataset_images', img_grid)\n",
    "\n",
    "# Keeps track of how often we train the model,\n",
    "# this way we will see the loss logs in different plots.\n",
    "n_runs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "net = UNet(bilinear=True)\n",
    "\n",
    "criterion = nn.MSELoss() # average loss over the whole reconstructed image.\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Add a scheme of our network to Tensorboard.\n",
    "writer.add_graph(net.cpu(), data['image'])\n",
    "writer.close()\n",
    "\n",
    "writer = SummaryWriter('runs/{}'.format(n_runs))\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(1):\n",
    "    running_loss = 0.0\n",
    "    valiter = iter(valloader)\n",
    "    for i, data in enumerate(trainloader, start=0):\n",
    "        inputs = data['image']\n",
    "        labels = data['image']\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Log the loss to Tensorboard,\n",
    "        # giving a nice loss over time.\n",
    "        writer.add_scalar('Loss/train', \n",
    "                          loss.item(), \n",
    "                          epoch * len(trainloader) + i)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            # Get images and swap axes.\n",
    "            image_output = outputs[0].detach().numpy().T\n",
    "            image_output = np.swapaxes(image_output, 0, 1)\n",
    "            image_input = labels[0].detach().numpy().T\n",
    "            image_input = np.swapaxes(image_input, 0, 1)\n",
    "\n",
    "            # Add a comparison between input and output image to Tensorboard.\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "            ax1.imshow(image_input)\n",
    "            ax2.imshow((image_output * 255).astype(np.uint8))\n",
    "\n",
    "            writer.add_figure('input vs. output',\n",
    "                              fig,\n",
    "                              global_step=epoch * len(trainloader) + i)\n",
    "            \n",
    "            # For now do the validation at the same frequency as the image feedback.\n",
    "            val_data = valiter.next()\n",
    "            val_inputs = val_data['image']\n",
    "            val_outputs = net(val_inputs)\n",
    "            \n",
    "            val_loss = criterion(val_outputs, val_inputs)\n",
    "            \n",
    "            # Write the validation loss to Tensorboard.\n",
    "            writer.add_scalar('Loss/val',\n",
    "                              val_loss.item(),\n",
    "                              epoch * len(trainloader) + i)\n",
    "            \n",
    "            # Instead of plotting training and validation loss on one graph,\n",
    "            # create a third graph that shows the divergence.\n",
    "            writer.add_scalar('Loss/divergence',\n",
    "                              val_loss.item() - loss.item(),\n",
    "                              epoch * len(trainloader) + i)\n",
    "\n",
    "        if i == 100:\n",
    "            break\n",
    "\n",
    "n_runs = n_runs + 1\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the feature maps for the latent space.\n",
    "# Probably we want to either change either\n",
    "# the latent space itself or the visualisation.\n",
    "\n",
    "# Calling 'data' on weights makes\n",
    "# a copy of the tensor for local use.\n",
    "latent_conv_weights = net.down4.maxpool_conv[1].double_conv[3].weight.data\n",
    "\n",
    "for i, kernel in enumerate(latent_conv_weights[0]):\n",
    "    fig, ax1 = plt.subplots(1, 1)\n",
    "    ax1.imshow((kernel.numpy()))\n",
    "    writer.add_figure('Latent space weights',\n",
    "                      fig,\n",
    "                      global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
